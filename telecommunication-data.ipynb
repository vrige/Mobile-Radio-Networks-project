{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport pylab \nimport scipy.stats as stats\nfrom sklearn.metrics import auc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","metadata":{"id":"yyo7Y0BFPEzJ","execution":{"iopub.status.busy":"2022-08-31T08:47:53.676599Z","iopub.execute_input":"2022-08-31T08:47:53.677064Z","iopub.status.idle":"2022-08-31T08:47:54.399948Z","shell.execute_reply.started":"2022-08-31T08:47:53.676975Z","shell.execute_reply":"2022-08-31T08:47:54.398566Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#USEFUL FUNCTIONS FOR PLOTTING\n\ndef plot_cdf(data, votes, bin_edges, ax, xlabel=None, color=None):\n\n    '''\n    This function is useful to understand whether in inout feature \"data\" there is information which is correlated to the\n    satisfaction of the users.\n    Generally speaking, the meaning of the CDFs is that, if there is a gap between the distributions of the data\n    conditioned to the satisfaction class of the corresponding users, it means that the information in the data is\n    correlated to users satisfaction and thus can be learnt by a supervised classifier.\n    Generally speaking, looking at data distributions is the first step to decide whether some data may be useful or\n    not for ML problems.\n    :param data: data to be plot (one-dimensional array)\n    :param votes: satisfaction labels, int; if already binary, set threshold to None\n    :param bin_edges: array of type  np.linspace(min(data), max(data), num_bins+1)\n    :param ax: axis of type plt.subplots(figsize=(a,b));\n    :param xlabel: label to gice to x axis\n    :param color: axis color\n    :return:\n    '''\n\n    if xlabel is None:\n        xlabel = 'your data'\n    if color is None:\n        color = 'black'\n\n    yt = votes.copy()\n\n    neg, _ = np.histogram(data[yt == +1], bins=bin_edges)  # count number of evidences per bin\n    pos, _ = np.histogram(data[yt == 0], bins=bin_edges)\n\n    sumpos =  sum(pos)\n    sumneg =  sum(neg)\n    pos = pos.astype(float) / sumpos  # normalize to total number of evidences\n    neg = neg.astype(float) / sumneg\n\n    xrange = bin_edges[1:] - bin_edges[:1]\n    \n    title = 'CDF'\n    ax.plot(xrange, np.cumsum(pos))\n    ax.plot(xrange, np.cumsum(neg))\n    ax.xaxis.label.set_color(color)\n    ax.yaxis.label.set_color(color)\n    ax.tick_params(axis='x', colors=color)\n    ax.tick_params(axis='y', colors=color)\n    ax.xaxis.grid(True)\n    ax.yaxis.grid(True)\n    ax.set_xlabel(xlabel)\n    ax.set_title(title, color=color)\n    ax.legend(['High QoE', 'Low QoE'])\n    return\n\n# USEFUL FUNCTIONS FOR PREDICTION\n\ndef hyperparameter_tuning(train_sample, train_target, names, classifiers, parameters_grid,\n                          n_splits_in=None, ref_metric=None):\n    '''\n    This function applies a cross validation strategy to select, for each of the classifiers provided in input, \n    the best hyper-parameters (hp) values out of a pool of candidate values (Grid Search Procedure). \n    The function saves on a file the best hp values, for the input Training Fold. Finally, it returns the prediction \n    performance on the input Validation Fold.\n    (ref: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/)\n\n    :param train_sample: training samples set\n    :param train_target: training users satisfaction labels\n    :param test_sample: test samples set\n    :param test_target: test users satisfaction labels\n    :param names: involved classifiers names\n    :param classifiers: involved classifiers scikitlearn functions\n    :param n_splits_in: number of k fold splits for validation (our results were derived with 10 folds, which is the default value)\n    :param ref_metric: optimization metric (sklearn.metrics); default roc_auc\n    :return: prediction performance on the test set (AUC)\n    '''\n\n    if ref_metric is None:\n        ref_metric = 'roc_auc'\n    if n_splits_in is None:\n        n_splits_in = 2\n\n    best_hp = pd.DataFrame(index = names, columns = ['BestHP_Values'])\n    print('Choose Best hyper-parameters through Cross Validation')\n    text_file = open('Best_hyper-parameters (HP Tuning).txt', \"w\") # If this filename already exists in folder, \n    # results will be appended to older file. Delete older version to fill a new txt file.\n    text_file.write(\"############\\n\")\n    for name, clf in zip(names, classifiers):\n        text_file.write(\"{}:\\n\".format(name))\n        print(\"############\")\n        print(' Classifier {} - Processing'.format(name))\n        grid = parameters_grid[names.index(name)] #take hyper-parameters candidate values grid \n        estimator = model_selection.GridSearchCV(clf, grid, scoring=ref_metric,refit=True,\n                                                 cv=n_splits_in).fit(train_sample, train_target) #Grid Search \n        bp = estimator.best_params_\n        print(' Best Parameters Values: {}'.format(bp))\n        print(list(bp.values()))\n        best_hp.at[name,'BestHP_Values'] = list(bp.values())\n        text_file.write(\"{}:\\n\".format(estimator.best_params_))\n        text_file.write(\"############\\n\")\n        print(\"############\")\n    text_file.write(\"******************\\n\")\n    text_file.close()\n\n    return best_hp\n    \n\ndef direct_prediction(train_sample, train_target, test_sample, test_target, names, classifiers):\n    '''\n    This function takes in input a group of classifiers with already fixed HP values, train them on the input data \n    train_sample --> train_target and finally performs prediction on the input test_sample-->test_target. \n    \n    Note that each classifier outputs the probability that a given test user belongs to the\n    class of Dissatisfied Users. By thresholding such probability, one can effectively assign to the test user \n    either the Satisfied ('0') or the Dissatisfied ('1') label. Computing the FPR and TPR of the classifier for \n    different threshold values, it is possible to draw a ROC Curve.\n    Finally, the performance in terms of Area Under the ROC Curve are returned as output.\n    (ref: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)\n    \n    \n    :param train_sample: training samples set\n    :param train_target: training users satisfaction labels\n    :param test_sample: test samples set\n    :param test_target: test users satisfaction labels\n    :param names: names of the considered classifiers \n    :param classifiers: the scikit methods corresponding to the considered classifiers\n    :return: prediction performance (AUC) on the test set\n    '''\n    \n    perf = pd.DataFrame(index=names,columns=['AUC'])\n    prediction_proba = np.empty((len(names), len(test_sample)))\n\n    plt.figure(figsize=(20, 5))\n    color = ['b', 'r', 'g', 'c', 'k', 'm'] #choose a color for each classifier\n    color = color[:len(names)]\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.3) # ROC Curve of a dummy \n    # Classifier\n    for name, clf in zip(names, classifiers):\n        print(' Classifier {} - Fit & Predict'.format(name))\n        estimator = clf.fit(train_sample, train_target) # fit the classifier on training set\n\n        prediction_proba[names.index(name),:] = estimator.predict_proba(test_sample)[:, 1] # generate, for each test\n        # user, the probability that the user is not satisfied\n\n        fpr, tpr, decision_thresholds = metrics.roc_curve(test_target, prediction_proba[names.index(name),:]\n                                                          , pos_label=1)\n\n        perf.at[name,'AUC'] = metrics.auc(fpr, tpr)\n        plt.plot(fpr, tpr, color=color[names.index(name)], label=r'ROC %s (AUC = %0.3f)' % (name,perf.loc[name,\n                                                                                                          'AUC']), lw=2, alpha=.8)\n        perf.at[name,'AUC'] = metrics.auc(fpr, tpr)\n    \n    plt.plot(0, 1, '*', color='k', label=r'Optimum: FPR = 0, TPR = 1', lw=2, alpha=.8, markersize=15)\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xticks(color='black')\n    plt.yticks(color='black')\n    plt.grid(1)\n    plt.xlabel('False Positive Rate', color='black', fontsize=14)\n    plt.ylabel('True Positive Rate', color='black', fontsize=14)\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    #plt.savefig('ROC.png', bbox_inches='tight') #uncomment to save the plot\n    return perf\n\n\n        ","metadata":{"id":"o0k4RwVXPEzL","execution":{"iopub.status.busy":"2022-08-31T08:47:56.183121Z","iopub.execute_input":"2022-08-31T08:47:56.183535Z","iopub.status.idle":"2022-08-31T08:47:56.213718Z","shell.execute_reply.started":"2022-08-31T08:47:56.183501Z","shell.execute_reply":"2022-08-31T08:47:56.212258Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Import Training Data","metadata":{"id":"m_Ox_IriPEzM"}},{"cell_type":"code","source":"'''\nif 'dataset' in globals():\n    del dataset\nif 'ground_truth' in globals():\n    del ground_truth\n'''\n\npath = '../input/basicdataset-training-mrn' # PUT YOUR FILE PATH\nbasic_train = pd.read_csv(path + '/BasicDataset_Training_MRN.csv')\nbasic_test = pd.read_csv('../input/basicdataset-test-mrn/BasicDataset_Test_MRN.csv')\n\ndataset = basic_train.drop(['User_Satisfaction','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\ntestset = basic_test.drop(['User_Satisfaction','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\nground_truth = basic_train.loc[:, 'User_Satisfaction'].copy()\ntest_truth = basic_test.loc[:, 'User_Satisfaction'].copy()\n\nprint('Train Data:', dataset.shape)\nprint('Train Target:', ground_truth.shape)\n\nprint('Test Data:', testset.shape)\nprint('Train Target:', test_truth.shape)","metadata":{"id":"-Al1SOxfPEzM","outputId":"900dd012-edf5-488a-81e2-f421be46b3d9","execution":{"iopub.status.busy":"2022-08-31T08:47:56.512327Z","iopub.execute_input":"2022-08-31T08:47:56.512749Z","iopub.status.idle":"2022-08-31T08:47:56.634861Z","shell.execute_reply.started":"2022-08-31T08:47:56.512711Z","shell.execute_reply":"2022-08-31T08:47:56.633640Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"list(dataset.columns)\ndataset.head()","metadata":{"id":"stN0psG5PEzN","outputId":"75446fec-1a61-4d55-95aa-64412d7538c2","execution":{"iopub.status.busy":"2022-08-31T08:47:56.637052Z","iopub.execute_input":"2022-08-31T08:47:56.637428Z","iopub.status.idle":"2022-08-31T08:47:56.663618Z","shell.execute_reply.started":"2022-08-31T08:47:56.637396Z","shell.execute_reply":"2022-08-31T08:47:56.662355Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ground_truth.value_counts()\nground_truth.head()","metadata":{"id":"wGeDTDT2PEzN","outputId":"6b48dd20-1664-4927-c6e3-9a67ce05779d","execution":{"iopub.status.busy":"2022-08-31T08:47:56.665204Z","iopub.execute_input":"2022-08-31T08:47:56.665642Z","iopub.status.idle":"2022-08-31T08:47:56.678586Z","shell.execute_reply.started":"2022-08-31T08:47:56.665607Z","shell.execute_reply":"2022-08-31T08:47:56.677563Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{"id":"eA4gI52-PEzO"}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf = basic_train.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\ncorr = df.corr()\nfig, ax = plt.subplots()\nfig.set_size_inches(8, 6)\nsns.heatmap(corr, annot=True, fmt='.2f', \n            cmap=plt.get_cmap('coolwarm'), cbar=False, ax=ax)\nax.set_yticklabels(ax.get_yticklabels(), rotation=\"horizontal\")\nplt.savefig('result.png', bbox_inches='tight', pad_inches=20.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:47:56.680192Z","iopub.execute_input":"2022-08-31T08:47:56.680634Z","iopub.status.idle":"2022-08-31T08:47:59.618010Z","shell.execute_reply.started":"2022-08-31T08:47:56.680599Z","shell.execute_reply":"2022-08-31T08:47:59.616758Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 1 Cumulative_YoutubeSess_LTE_DL_Volume\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 5))\nx = dataset.iloc[:,1].copy()\nprint(\"number of zeros: {}. %: {}\".format(len(x[x==0]),len(x[x==0])/len(x) ))\nx[x==0] = 1.000001\ntmp_0 = ax.hist(np.log(x), bins=100)\n#tmp_0 = ax.hist(x, bins=100)\nax.set_ylabel('Bincount')\nax.xaxis.label.set_color('red')\nax.yaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:47:59.620594Z","iopub.execute_input":"2022-08-31T08:47:59.621108Z","iopub.status.idle":"2022-08-31T08:48:00.053206Z","shell.execute_reply.started":"2022-08-31T08:47:59.621049Z","shell.execute_reply":"2022-08-31T08:48:00.051640Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 1 Cumulative_YoutubeSess_LTE_DL_Volume\n\nmeasurements = np.random.normal(loc = 20, scale = 5, size=100)   \nstats.probplot(np.log(x), dist=\"norm\", plot=pylab)\npylab.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:00.054979Z","iopub.execute_input":"2022-08-31T08:48:00.055394Z","iopub.status.idle":"2022-08-31T08:48:00.344090Z","shell.execute_reply.started":"2022-08-31T08:48:00.055341Z","shell.execute_reply":"2022-08-31T08:48:00.343098Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 3 \n\nfig, ax = plt.subplots(1, 1, figsize=(20, 5))\nx = dataset.iloc[:,5].copy()\nprint(\"number of zeros: {}. %: {}\".format(len(x[x==0]),len(x[x==0])/len(x) ))\nx[x==0] = 1.000001\ntmp_0 = ax.hist(x, bins=100)\n#tmp_0 = ax.hist(x, bins=100)\nax.set_ylabel('Bincount')\nax.xaxis.label.set_color('red')\nax.yaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:00.345603Z","iopub.execute_input":"2022-08-31T08:48:00.346541Z","iopub.status.idle":"2022-08-31T08:48:00.763392Z","shell.execute_reply.started":"2022-08-31T08:48:00.346493Z","shell.execute_reply":"2022-08-31T08:48:00.762431Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Python3 code to show Box-cox Transformation\n# of non-normal data\n \n# import modules\nimport numpy as np\nfrom scipy import stats\n \n# plotting modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import boxcox\n \n# generate non-normal data (exponential)\noriginal_data= dataset.iloc[:,2].copy()\noriginal_data[original_data == 0] = 1.000001\n \n# transform training data & save lambda value\nfitted_data, fitted_lambda = stats.boxcox(original_data)\n \n# creating axes to draw plots\nfig, ax = plt.subplots(1, 2)\n \n# plotting the original data(non-normal) and\n# fitted data (normal)\nsns.distplot(original_data, hist = False, kde = True,\n            kde_kws = {'shade': True, 'linewidth': 2},\n            label = \"Non-Normal\", color =\"green\", ax = ax[0])\n \nsns.distplot(fitted_data, hist = False, kde = True,\n            kde_kws = {'shade': True, 'linewidth': 2},\n            label = \"Normal\", color =\"green\", ax = ax[1])\n \n# adding legends to the subplots\nplt.legend(loc = \"upper right\")\n \n# rescaling the subplots\nfig.set_figheight(5)\nfig.set_figwidth(10)\n \nprint(f\"Lambda value used for Transformation: {fitted_lambda}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:00.772301Z","iopub.execute_input":"2022-08-31T08:48:00.773035Z","iopub.status.idle":"2022-08-31T08:48:01.485688Z","shell.execute_reply.started":"2022-08-31T08:48:00.772996Z","shell.execute_reply":"2022-08-31T08:48:01.484354Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# let's try to combine most of the features\n\nc = dataset.copy()\nc = c.drop(['Cumulative_YoutubeSess_LTE_DL_Time','Cumulative_YoutubeSess_LTE_DL_Volume','Cumulative_Lim_Service_Time_LTE',\n            'Cumulative_Lim_Service_Time_UMTS','Cumulative_YoutubeSess_UMTS_DL_Time','Cumulative_Full_Service_Time_UMTS',\n            'Cumulative_No_Service_Time_UMTS','Cumulative_Full_Service_Time_LTE','Cumulative_No_Service_Time_LTE'], axis=1)\nt = testset.copy()\nt = t.drop(['Cumulative_YoutubeSess_LTE_DL_Time','Cumulative_YoutubeSess_LTE_DL_Volume','Cumulative_Lim_Service_Time_LTE',\n            'Cumulative_Lim_Service_Time_UMTS','Cumulative_YoutubeSess_UMTS_DL_Time','Cumulative_Full_Service_Time_UMTS',\n            'Cumulative_No_Service_Time_UMTS','Cumulative_Full_Service_Time_LTE','Cumulative_No_Service_Time_LTE'], axis=1)\n\nc1 = c.copy()\nc2 = c.copy()\nc3 = c.copy()\nc4 = dataset.copy()\n\nt1 = t.copy()\nt2 = t.copy()\nt3 = t.copy()\nt4 = testset.copy()\n\n\nx0 = dataset['Cumulative_YoutubeSess_LTE_DL_Time'].copy()\nx0[x0==0] = 1.000001\nx0a = (np.divide(dataset['Cumulative_YoutubeSess_LTE_DL_Volume'],x0)).copy()\nx = dataset['Cumulative_Full_Service_Time_LTE'] + dataset['Cumulative_Full_Service_Time_UMTS']\nx1 = dataset['Cumulative_Lim_Service_Time_LTE'] + dataset['Cumulative_Lim_Service_Time_UMTS']\nx2 = x + x1\nx3 = dataset['Cumulative_No_Service_Time_LTE'] + dataset['Cumulative_No_Service_Time_UMTS']\nx4 = dataset['Cumulative_YoutubeSess_LTE_DL_Time'] + dataset['Cumulative_YoutubeSess_UMTS_DL_Time']\nx5 = dataset['Cumulative_YoutubeSess_LTE_DL_Volume'] + dataset['Cumulative_YoutubeSess_UMTS_DL_Volume']\nx4[x4 == 0] = 1.00001\nx6 = x5 / x4\nlog_x = ['Cumulative_Full_Service_Time_UMTS','Cumulative_No_Service_Time_UMTS','Cumulative_Full_Service_Time_LTE']\n\n\nt_x0 = testset['Cumulative_YoutubeSess_LTE_DL_Time'].copy()\nt_x0[t_x0==0] = 1.000001\nt_x0a = (np.divide(testset['Cumulative_YoutubeSess_LTE_DL_Volume'],t_x0)).copy()\nt_x = testset['Cumulative_Full_Service_Time_LTE'] + testset['Cumulative_Full_Service_Time_UMTS']\nt_x1 = testset['Cumulative_Lim_Service_Time_LTE'] + testset['Cumulative_Lim_Service_Time_UMTS']\nt_x2 = t_x + t_x1\nt_x3 = testset['Cumulative_No_Service_Time_LTE'] + testset['Cumulative_No_Service_Time_UMTS']\nt_x4 = testset['Cumulative_YoutubeSess_LTE_DL_Time'] + testset['Cumulative_YoutubeSess_UMTS_DL_Time']\nt_x5 = testset['Cumulative_YoutubeSess_LTE_DL_Volume'] + testset['Cumulative_YoutubeSess_UMTS_DL_Volume']\nt_x4[t_x4 == 0] = 1.00001\nt_x6 = t_x5 / t_x4\n\n\nc['Rate_LTE_DL'] = x0a\nc['Some_Service'] = x2\nc['No_Service'] = x3\nt['Rate_LTE_DL'] = t_x0a\nt['Some_Service'] = t_x2\nt['No_Service'] = t_x3\n\nc_sd = ((c - np.mean(c))/np.std(c)).copy()   \nt_sd = ((t - np.mean(c))/np.std(c)).copy()\n\n\nc1['Rate_LTE_DL'] = x0a\nc1['Cumulative_Full_Service_Time'] = x\nc1['Cumulative_Lim_Service_Time'] = x1\nc1['Cumulative_No_Service_Time'] = x3\nt1['Rate_LTE_DL'] = t_x0a\nt1['Cumulative_Full_Service_Time'] = t_x\nt1['Cumulative_Lim_Service_Time'] = t_x1\nt1['Cumulative_No_Service_Time'] = t_x3\n\nc1_sd = ((c1 - np.mean(c1))/np.std(c1)).copy()   \nt1_sd = ((t1 - np.mean(c1))/np.std(c1)).copy()\n\n\nc2['Cumulative_Full_Service_Time'] = x\nc2['Cumulative_Lim_Service_Time'] = x1\nc2['Cumulative_No_Service_Time'] = x3\nc2['Total_Rate'] = x6\nc2 = c2.drop(['Cumulative_YoutubeSess_UMTS_DL_Volume'], axis=1)\nt2['Cumulative_Full_Service_Time'] = t_x\nt2['Cumulative_Lim_Service_Time'] = t_x1\nt2['Cumulative_No_Service_Time'] = t_x3\nt2['Total_Rate'] = t_x6\nt2 = t2.drop(['Cumulative_YoutubeSess_UMTS_DL_Volume'], axis=1)\n\nc2_sd = ((c2 - np.mean(c2))/np.std(c2)).copy()   \nt2_sd = ((t2 - np.mean(c2))/np.std(c2)).copy()\n\n\nc3['Some_Service'] = x2\nc3['No_Service'] = x3\nc3['Total_Rate'] = x6\nc3 = c3.drop(['Cumulative_YoutubeSess_UMTS_DL_Volume'], axis=1)\nt3['Some_Service'] = t_x2\nt3['No_Service'] = t_x3\nt3['Total_Rate'] = t_x6\nt3 = t3.drop(['Cumulative_YoutubeSess_UMTS_DL_Volume'], axis=1)\n\nc3_sd = ((c3 - np.mean(c3))/np.std(c3)).copy()   \nt3_sd = ((t3 - np.mean(c3))/np.std(c3)).copy()\n\n\nc4['Rate_LTE_DL'] = x0a\nc4 = c4.drop(['Cumulative_YoutubeSess_LTE_DL_Time','Cumulative_YoutubeSess_LTE_DL_Volume',\n              'Cumulative_YoutubeSess_UMTS_DL_Time','Cumulative_Full_Service_Time_UMTS','Cumulative_No_Service_Time_UMTS',\n              'Cumulative_Full_Service_Time_LTE'], axis=1)\nt4['Rate_LTE_DL'] = t_x0a\nt4 = t4.drop(['Cumulative_YoutubeSess_LTE_DL_Time','Cumulative_YoutubeSess_LTE_DL_Volume',\n              'Cumulative_YoutubeSess_UMTS_DL_Time','Cumulative_Full_Service_Time_UMTS','Cumulative_No_Service_Time_UMTS',\n              'Cumulative_Full_Service_Time_LTE'], axis=1)\nfor s in log_x:\n    words = [\"log\",s]\n    words = \"_\".join(words)\n    temp = dataset[s].copy()\n    temp2 = testset[s].copy()\n    c4[words] = np.log(temp + 1)\n    t4[words] = np.log(temp2 + 1)\n    \n    \nc4_sd = ((c4 - np.mean(c4))/np.std(c4)).copy()   \nt4_sd = ((t4 - np.mean(c4))/np.std(c4)).copy()\n\n\n\nprint(\"c\\n\\n\",c.head())\nprint(\"t\\n\\n\",t.head())\n\nprint(\"c1\\n\\n\",c1.head())\nprint(\"t1\\n\\n\",t1.head())\n\nprint(\"c2\\n\\n\",c2.head())\nprint(\"t2\\n\\n\",t2.head())\n\nprint(\"c3\\n\\n\",c3.head())\nprint(\"t3\\n\\n\",t3.head())\n\nprint(\"c4\\n\\n\",c4.head())\nprint(\"t4\\n\\n\",t4.head())\n\nprint(\"c4_sd\\n\\n\",c4_sd.head())\nprint(\"t4_sd\\n\\n\",t4_sd.head())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:01.487689Z","iopub.execute_input":"2022-08-31T08:48:01.488059Z","iopub.status.idle":"2022-08-31T08:48:01.673899Z","shell.execute_reply.started":"2022-08-31T08:48:01.488025Z","shell.execute_reply":"2022-08-31T08:48:01.672713Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df = c4.copy()\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:01.677807Z","iopub.execute_input":"2022-08-31T08:48:01.678186Z","iopub.status.idle":"2022-08-31T08:48:01.780797Z","shell.execute_reply.started":"2022-08-31T08:48:01.678152Z","shell.execute_reply":"2022-08-31T08:48:01.779541Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Standardization\ndf = c4_sd.copy()\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:01.782105Z","iopub.execute_input":"2022-08-31T08:48:01.782957Z","iopub.status.idle":"2022-08-31T08:48:01.822974Z","shell.execute_reply.started":"2022-08-31T08:48:01.782922Z","shell.execute_reply":"2022-08-31T08:48:01.821698Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# PCA\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = c4_sd.copy()\n\npca = PCA()\npca.fit(X)\n\nstd_slc = StandardScaler()\nX_std = std_slc.fit_transform(X)\nX_std_pca = pca.fit_transform(X_std) # scores\n\nprint(\"Explained variance ratio: {}\".format(pca.explained_variance_ratio_))\ns = 0\nvec = []\n\nfor s1 in pca.explained_variance_ratio_:\n    s = s + s1\n    vec.append(s)\n    \nprint(\"Cumulative explained variance ratio: {}\".format(vec))\n    \n# we noticec that the first 8 explain a lot of the variability, so we deleted just two components \nX_std_pca = X_std_pca[:,0:8]\nX_std_pca = pd.DataFrame(X_std_pca, columns=['PC1', 'PC2','PC3','PC4','PC5','PC6','PC7','PC8'])\n#X_std_pca['Satisfaction'] = ground_truth\nprint(X_std_pca.head())\n\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\nloading_matrix = pd.DataFrame(loadings, columns=['PC1', 'PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])\n\ntest_std_pca = np.dot(t4_sd,loading_matrix)\ntest_std_pca = pd.DataFrame(test_std_pca[:,0:8],columns=X_std_pca.columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:01.850517Z","iopub.execute_input":"2022-08-31T08:48:01.850846Z","iopub.status.idle":"2022-08-31T08:48:01.957853Z","shell.execute_reply.started":"2022-08-31T08:48:01.850816Z","shell.execute_reply":"2022-08-31T08:48:01.955942Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Is the dataset balanced?\nnum_1 = sum(ground_truth[ground_truth == 1])\nprop_1 = num_1/len(ground_truth)\n\nnum_2 = len(ground_truth) - num_1\nprop_2 = num_2/len(ground_truth)\nprint(\"number of 1s is: {}, while the number of 0s is: {}\".format(num_1,num_2) )\nprint(\"proportion of 1s is: {}, while proportion of 0s is: {}\".format(prop_1,prop_2) )\n\n#it's slightly unbalanced. We can performe some oversampling techniques \n\n# Random oversampling to balance the class distribution\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\n\n# summarize class distribution\nprint(Counter(ground_truth))\n# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')\n# fit and apply the transform\nc5, ground_truth_5 = oversample.fit_resample(c4, ground_truth)\n# summarize class distribution\nprint(Counter(ground_truth_5))\n\nc5_sd = ((c5 - np.mean(c5))/np.std(c5)).copy()   \nt5_sd = ((t4 - np.mean(c5))/np.std(c5)).copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:01.960971Z","iopub.execute_input":"2022-08-31T08:48:01.964002Z","iopub.status.idle":"2022-08-31T08:48:02.537738Z","shell.execute_reply.started":"2022-08-31T08:48:01.963934Z","shell.execute_reply":"2022-08-31T08:48:02.536423Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# check on the correctness of the scores for the testset\n# print(loading_matrix.iloc[:,0])\n# print(t_sd.iloc[0,:])\n# print(np.dot(loading_matrix.iloc[:,0],t_sd.iloc[0,:])) # first score of the first component\n# print(test_std_pca.iloc[0,0])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:02.539138Z","iopub.execute_input":"2022-08-31T08:48:02.540163Z","iopub.status.idle":"2022-08-31T08:48:02.545766Z","shell.execute_reply.started":"2022-08-31T08:48:02.540124Z","shell.execute_reply":"2022-08-31T08:48:02.544355Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# to write the new data in a csv file\n# X.to_csv (r'dataaa.csv', index = False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:02.547066Z","iopub.execute_input":"2022-08-31T08:48:02.547769Z","iopub.status.idle":"2022-08-31T08:48:02.557715Z","shell.execute_reply.started":"2022-08-31T08:48:02.547732Z","shell.execute_reply":"2022-08-31T08:48:02.556519Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Function to calculate True Positive Rate and False Positive Rate\n\ndef calc_TP_FP_rate(y_true, y_pred):\n    \n    # Convert predictions to series with index matching y_true\n    y_pred = pd.Series(y_pred, index=y_true.index)\n    \n    # Instantiate counters\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    # Determine whether each prediction is TP, FP, TN, or FN\n    for i in y_true.index: \n        if y_true[i]==y_pred[i]==1:\n           TP += 1\n        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n           FP += 1\n        if y_true[i]==y_pred[i]==0:\n           TN += 1\n        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n           FN += 1\n    \n    # Calculate true positive rate and false positive rate\n    tpr = TP / (TP + FN)\n    fpr = FP / (FP + TN)\n\n    return tpr, fpr\n\n# Test function","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:02.559494Z","iopub.execute_input":"2022-08-31T08:48:02.560704Z","iopub.status.idle":"2022-08-31T08:48:02.570689Z","shell.execute_reply.started":"2022-08-31T08:48:02.560662Z","shell.execute_reply":"2022-08-31T08:48:02.569374Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# lists for saving models and results\nmodels = []\npreds = []\nauc_l = []\ndataset_l = []\nsolver_l = []\npenalty_l = []\nc_l = []","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:02.572490Z","iopub.execute_input":"2022-08-31T08:48:02.572899Z","iopub.status.idle":"2022-08-31T08:48:02.587113Z","shell.execute_reply.started":"2022-08-31T08:48:02.572849Z","shell.execute_reply":"2022-08-31T08:48:02.585804Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# 0 - CrossValidation with logisticRegression on the original data\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3,random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc',refit=True, n_jobs=-1,cv=cv)\n# execute search\nresult = search.fit(dataset,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6181891168533392\n# Best Hyperparameters: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:02.588218Z","iopub.execute_input":"2022-08-31T08:48:02.588607Z","iopub.status.idle":"2022-08-31T08:48:35.201799Z","shell.execute_reply.started":"2022-08-31T08:48:02.588575Z","shell.execute_reply":"2022-08-31T08:48:35.200484Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# 0b - LogisticRegression on the original data \n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='liblinear',penalty='l1',C = 1000 ,random_state=0)\nmodel.fit(dataset, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(testset)\npredd = model.score(testset, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(testset))))\n\ny_test_probs = model.predict_proba(testset)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"dataset\")\nsolver_l.append(\"liblinear\")\npenalty_l.append(\"l1\")\nc_l.append(1000)\n\n# results:\n# intercept [-0.69278593], coef [[ 6.24708093e-05 -1.61327154e-07  1.27366935e-04 -7.22990659e-07\n#   -8.04987193e-02 -6.70831241e-03 -9.31903442e-06  8.14338374e-05\n#    3.29723019e-05 -1.93030926e-06  5.35052302e-05  9.52176101e-06]]\n# accuracy on prediction: 0.6797385620915033\n# Confusion matrix:\n#  [[3113  108]\n#  [1411  111]]\n# Logistic Regression (No reg.) AUC 0.6256044535266877","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:35.204112Z","iopub.execute_input":"2022-08-31T08:48:35.204715Z","iopub.status.idle":"2022-08-31T08:48:49.919906Z","shell.execute_reply.started":"2022-08-31T08:48:35.204660Z","shell.execute_reply":"2022-08-31T08:48:49.918550Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# 0c - CrossValidation with logisticRegression on c_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c_sd,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.5837018758075153\n# Best Hyperparameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:48:49.921516Z","iopub.execute_input":"2022-08-31T08:48:49.921926Z","iopub.status.idle":"2022-08-31T08:49:06.911464Z","shell.execute_reply.started":"2022-08-31T08:48:49.921893Z","shell.execute_reply":"2022-08-31T08:49:06.910186Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# 0d - LogisticRegression on c_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='liblinear',penalty='l2',C = 0.001, random_state=0)\nmodel.fit(c_sd, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t_sd)\npredd = model.score(t_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t_sd))))\n\ny_test_probs = model.predict_proba(t_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c_sd\")\nsolver_l.append(\"liblinear\")\npenalty_l.append(\"l2\")\nc_l.append(0.001)\n\n# results:\n# intercept [-0.5885437], coef [[-0.01479649 -0.09051643 -0.09862094 -0.06723762 -0.17436779  0.0351862 ]]\n# accuracy on prediction: 0.6810035842293907\n# Confusion matrix:\n#  [[3212    9]\n#  [1504   18]]\n# Logistic Regression (No reg.) AUC 0.597905050667413","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:49:06.913244Z","iopub.execute_input":"2022-08-31T08:49:06.913633Z","iopub.status.idle":"2022-08-31T08:49:21.553620Z","shell.execute_reply.started":"2022-08-31T08:49:06.913599Z","shell.execute_reply":"2022-08-31T08:49:21.552689Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# 1 - CrossValidation with logisticRegression on c1_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c1_sd,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6055966218461358\n# Best Hyperparameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:49:21.554754Z","iopub.execute_input":"2022-08-31T08:49:21.555539Z","iopub.status.idle":"2022-08-31T08:49:40.152114Z","shell.execute_reply.started":"2022-08-31T08:49:21.555504Z","shell.execute_reply":"2022-08-31T08:49:40.150934Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# 1a - LogisticRegression on c1_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='saga', penalty='l2',C = 0.001 ,random_state=0)\nmodel.fit(c1_sd, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t1_sd)\npredd = model.score(t1_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t1_sd))))\n\ny_test_probs = model.predict_proba(t1_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint('Logistic Regression (No reg.) AUC {}'.format(auc(lr_fp_rates, lr_tp_rates)))\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c1_sd\")\nsolver_l.append(\"saga\")\npenalty_l.append(\"l2\")\nc_l.append(0.001)\n\n# results: \n# intercept [-0.73311552], coef [[-0.0148945  -0.09430394 -0.10359717 -0.07015207 -0.18855392  0.16246657\n#    0.03656921]]\n# accuracy on prediction: 0.6791060510225596\n# Confusion matrix:\n#  [[3198   23]\n#  [1499   23]]\n# logistic Regression (No reg.) AUC 0.6187158353463086","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:49:40.154314Z","iopub.execute_input":"2022-08-31T08:49:40.155193Z","iopub.status.idle":"2022-08-31T08:49:54.701132Z","shell.execute_reply.started":"2022-08-31T08:49:40.155153Z","shell.execute_reply":"2022-08-31T08:49:54.699545Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# 2 - CrossValidation with logisticRegression on c2_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c2_sd,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6065395800274344\n# Best Hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:49:54.702660Z","iopub.execute_input":"2022-08-31T08:49:54.703440Z","iopub.status.idle":"2022-08-31T08:50:13.065207Z","shell.execute_reply.started":"2022-08-31T08:49:54.703395Z","shell.execute_reply":"2022-08-31T08:50:13.063856Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 2a - LogisticRegression on c2_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='saga', penalty='l2',C = 0.01, random_state=0)\nmodel.fit(c2_sd, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t2_sd)\npredd = model.score(t2_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t2_sd))))\n\ny_test_probs = model.predict_proba(t2_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c2_sd\")\nsolver_l.append(\"saga\")\npenalty_l.append(\"l2\")\nc_l.append(0.01)\n\n# results:\n# intercept [-0.7407721], coef [[-0.12778345 -0.13892725 -0.23089109  0.199131    0.04443668 -0.10084862]]\n# accuracy on prediction: 0.6793168880455408\n# Confusion matrix:\n#  [[3160   61]\n#  [1460   62]]\n# Logistic Regression (No reg.) AUC 0.61672852800344","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:50:13.067261Z","iopub.execute_input":"2022-08-31T08:50:13.067732Z","iopub.status.idle":"2022-08-31T08:50:27.654038Z","shell.execute_reply.started":"2022-08-31T08:50:13.067687Z","shell.execute_reply":"2022-08-31T08:50:27.652922Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# 3 - CrossValidation with logisticRegression on c3_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c3_sd,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.5850336573664553\n# Best Hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:50:27.655735Z","iopub.execute_input":"2022-08-31T08:50:27.656250Z","iopub.status.idle":"2022-08-31T08:50:44.215484Z","shell.execute_reply.started":"2022-08-31T08:50:27.656193Z","shell.execute_reply":"2022-08-31T08:50:44.213820Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# 3a - LogisticRegression on c3_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='liblinear', penalty='l2',C = 0.01, random_state=0)\nmodel.fit(c3_sd, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t3_sd)\npredd = model.score(t3_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t3_sd))))\n\ny_test_probs = model.predict_proba(t3_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c3_sd\")\nsolver_l.append(\"liblinear\")\npenalty_l.append(\"l2\")\nc_l.append(0.01)\n\n# results:\n# intercept [-0.71593362], coef [[-0.12489584 -0.13473968 -0.21839289  0.04386749 -0.09953964]]\n# accuracy on prediction: 0.6805819101834282\n# Confusion matrix:\n#  [[3206   15]\n#  [1500   22]]\n# Logistic Regression (No reg.) AUC 0.5976721017338172","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:50:44.221369Z","iopub.execute_input":"2022-08-31T08:50:44.221846Z","iopub.status.idle":"2022-08-31T08:50:58.605722Z","shell.execute_reply.started":"2022-08-31T08:50:44.221814Z","shell.execute_reply":"2022-08-31T08:50:58.604519Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# 4 - CrossValidation with logisticRegression on c4_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c4_sd,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6289946077164603\n# Best Hyperparameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:50:58.607831Z","iopub.execute_input":"2022-08-31T08:50:58.608298Z","iopub.status.idle":"2022-08-31T08:51:21.106795Z","shell.execute_reply.started":"2022-08-31T08:50:58.608254Z","shell.execute_reply":"2022-08-31T08:51:21.105690Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# 4a - LogisticRegression on c4_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='liblinear', penalty='l2',C = 0.001, random_state=0)\nmodel.fit(c4_sd, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t4_sd)\npredd = model.score(t4_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t4_sd))))\n\ny_test_probs = model.predict_proba(t4_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c4_sd\")\nsolver_l.append(\"liblinear\")\npenalty_l.append(\"l2\")\nc_l.append(0.001)\n\n# results:\n# intercept [-0.59304071], coef [[-0.01496925 -0.09180171 -0.09934159  0.14442221  0.068932    0.02632641\n#   -0.0684977  -0.25355605  0.03641513 -0.10105887]]\n# accuracy on prediction: 0.6883828800337339\n# Confusion matrix:\n#  [[3111  110]\n#  [1368  154]]\n# Logistic Regression (No reg.) AUC 0.6361301960157165\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:51:21.108301Z","iopub.execute_input":"2022-08-31T08:51:21.108704Z","iopub.status.idle":"2022-08-31T08:51:35.628932Z","shell.execute_reply.started":"2022-08-31T08:51:21.108670Z","shell.execute_reply":"2022-08-31T08:51:35.627654Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# 5 - CrossValidation with logisticRegression on X_std_pca\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(X_std_pca,ground_truth )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6124305265311364\n# Best Hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:51:35.630289Z","iopub.execute_input":"2022-08-31T08:51:35.630792Z","iopub.status.idle":"2022-08-31T08:51:54.953340Z","shell.execute_reply.started":"2022-08-31T08:51:35.630755Z","shell.execute_reply":"2022-08-31T08:51:54.952006Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# 5a - LogisticRegression on X_std_pca\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='saga', penalty='l1',C = 0.1, random_state=0)\nmodel.fit(X_std_pca, ground_truth)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(test_std_pca)\npredd = model.score(test_std_pca, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\n# acc = np.count_nonzero(pred == test_truth)/len(test_truth)\n# print(\"accuracy on prediction: {}\".format(acc))\nprint(\"accuracy on prediction: {}\".format(model.score(test_std_pca, test_truth)))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(test_std_pca))))\n\ny_test_probs = model.predict_proba(test_std_pca)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"X_std_pca\")\nsolver_l.append(\"saga\")\npenalty_l.append(\"l1\")\nc_l.append(0.1)\n\n\n# results:\n# intercept [-0.74053783], coef [[ 0.         -0.01744303 -0.07252896 -0.223862    0.25787507 -0.06524403\n#    0.15524025  0.0866031 ]]\n# accuracy on prediction: 0.6866961838498841\n# Confusion matrix:\n#  [[3134   87]\n#  [1399  123]]\n# Logistic Regression (No reg.) AUC 0.6074691138679681","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:51:54.955348Z","iopub.execute_input":"2022-08-31T08:51:54.955848Z","iopub.status.idle":"2022-08-31T08:52:09.430976Z","shell.execute_reply.started":"2022-08-31T08:51:54.955800Z","shell.execute_reply":"2022-08-31T08:52:09.429819Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# 6 - CrossValidation with logisticRegression on c5_sd\n\n# define model\nmodel = LogisticRegression()\n# define evaluation\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n# define search space\nspace = dict()\nspace['solver'] = ['liblinear','saga']#,'newton-cg', 'lbfgs']\nspace['penalty'] = ['l2','l1']#, 'none', 'l2', 'elasticnet']\nspace['C'] = [  1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100,1000]\n#space['class_weight'] = ['balanced','auto']\n\nsearch = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(c5_sd,ground_truth_5 )\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)\n\n# results:\n# Best Score: 0.6308096004523736\n# Best Hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:52:09.432305Z","iopub.execute_input":"2022-08-31T08:52:09.432658Z","iopub.status.idle":"2022-08-31T08:52:39.745742Z","shell.execute_reply.started":"2022-08-31T08:52:09.432626Z","shell.execute_reply":"2022-08-31T08:52:39.744399Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 6a - LogisticRegression on c5_sd\n\n# let's use the parameters choosen by the previous cross-validation\nmodel = LogisticRegression(solver='saga', penalty='l1',C = 0.1, random_state=0)\nmodel.fit(c5_sd, ground_truth_5)\n\nprint(\"intercept {}, coef {}\".format(model.intercept_,model.coef_))\n\npred = model.predict(t5_sd)\npredd = model.score(t5_sd, test_truth)\nprint(\"accuracy on prediction: {}\".format(predd))\nprint(\"Confusion matrix:\\n {}\".format(confusion_matrix(test_truth, model.predict(t5_sd))))\n\ny_test_probs = model.predict_proba(t5_sd)[:,1]\n# Containers for true positive / false positive rates\nlr_tp_rates = []\nlr_fp_rates = []\n\n# Define probability thresholds to use, between 0 and 1\nprobability_thresholds = np.linspace(0,1,num=100)\n\n# Find true positive / false positive rate for each threshold\nfor p in probability_thresholds:\n    \n    y_test_preds = []\n    \n    for prob in y_test_probs:\n        if prob > p:\n            y_test_preds.append(1)\n        else:\n            y_test_preds.append(0)\n            \n    tp_rate, fp_rate = calc_TP_FP_rate(test_truth, y_test_preds)\n        \n    lr_tp_rates.append(tp_rate)\n    lr_fp_rates.append(fp_rate)\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(lr_fp_rates, lr_tp_rates, label='Logistic Regression')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.legend();\n\nprint(f'Logistic Regression (No reg.) AUC {auc(lr_fp_rates, lr_tp_rates)}')\nmodels.append(model)\npreds.append(predd)\nauc_l.append(auc(lr_fp_rates, lr_tp_rates))\ndataset_l.append(\"c5_sd\")\nsolver_l.append(\"saga\")\npenalty_l.append(\"l1\")\nc_l.append(0.1)\n\n# results:\n# intercept [0.0097279], coef [[-0.02142671 -0.13389792 -0.13818234  0.19113956  0.09035076  0.03315708\n#   -0.09103414 -0.36718629  0.04736628 -0.14834248]]\n# accuracy on prediction: 0.6088973223698081\n# Confusion matrix:\n#  [[2044 1177]\n#  [ 678  844]]\n# Logistic Regression (No reg.) AUC 0.6368032389285002","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:52:39.747528Z","iopub.execute_input":"2022-08-31T08:52:39.748005Z","iopub.status.idle":"2022-08-31T08:52:54.645375Z","shell.execute_reply.started":"2022-08-31T08:52:39.747959Z","shell.execute_reply":"2022-08-31T08:52:54.644056Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(preds)\nprint(auc_l)\nprint(dataset_l)\nprint(solver_l)\nprint(penalty_l)\nprint(c_l)\ngrid_data = pd.DataFrame({'dataset_name':dataset_l,'Predictions':preds,\n                          'Auc':auc_l,'Solver':solver_l,'Penalty':penalty_l,'C':c_l})\ngrid_data\n# [0.6824794433902593, 0.6814252582753532, 0.6791060510225596, 0.6791060510225596, 0.6810035842293907, 0.6879612059877714, 0.687539531941809]\n# [0.6193000435300371, 0.5955459837523218, 0.5330532506575402, 0.5328790489156043, 0.5401594170320347, 0.6337366559221861, 0.6053417719866464]\n# ['dataset', 'c_sd', 'c1_sd', 'c2_sd', 'c3_sd', 'c4_sd', 'X_std_pca']\n# ['liblinear', 'liblinear', 'saga', 'saga', 'liblinear', 'liblinear', 'liblinear']\n# ['l1', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1']\n# [0.001, 0.0001, 1e-05, 1e-05, 1e-05, 0.01, 0.01]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T08:52:54.647453Z","iopub.execute_input":"2022-08-31T08:52:54.647938Z","iopub.status.idle":"2022-08-31T08:52:54.668158Z","shell.execute_reply.started":"2022-08-31T08:52:54.647890Z","shell.execute_reply":"2022-08-31T08:52:54.667011Z"},"trusted":true},"execution_count":38,"outputs":[]}]}